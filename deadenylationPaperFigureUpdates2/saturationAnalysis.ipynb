{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# saturationAnalysis.ipynb\n",
    "## Marcus Viscardi,    September 06, 2024\n",
    "\n",
    "Taking ques from [subsamplingReadsVsProteinCoding.ipynb](../polyA_manuscriptPostReviewScripts/subsamplingReadsVsProteinCoding.ipynb) which came from the polyA paper and [README.md](../deadenylationPaperFigureUpdates/README.md) which details the stuff from the previous reviews\n",
    "\n",
    "The important add here is wanting to include the RNA-Seq libraries as a comparison against the nanopore libs. This will be a little annoying as I'll probably want to just use the gene_counts from the RNA-Seq data. In order to subsample gene counts I'll need to expand the stuff out and then back down. If we can do this I could also use the compressed on genes library from nanopore libs!"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c3e5aeba5402bd3"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from typing import Tuple\n",
    "\n",
    "import nanoporePipelineCommon as npCommon\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import re\n",
    "\n",
    "import seaborn as sea\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from icecream import ic\n",
    "from datetime import datetime\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from scipy.stats import mannwhitneyu, ks_2samp\n",
    "\n",
    "import pickle as pkl\n",
    "\n",
    "import random\n",
    "\n",
    "pd.set_option('display.width', 200)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "def __time_formatter__():\n",
    "    now = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    return f\"ic: {now} | > \"\n",
    "ic.configureOutput(prefix=__time_formatter__)\n",
    "\n",
    "_ = ic(\"Imports done!\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "rna_seq_dir = Path(\"/data16/joshua/working/240829_ESRNA-seqDESeq2\")\n",
    "libs_text_files = rna_seq_dir / \"240829_libsFile.txt\"\n",
    "counts_file = rna_seq_dir / \"240829_counts_AS.geneCt\"\n",
    "assert libs_text_files.exists()\n",
    "assert counts_file.exists()\n",
    "counts_file"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "873fbcc5f214a754",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "libs_dir_dict = {}\n",
    "libs_sample_dict = {}\n",
    "rev_libs_sample_dict = {}\n",
    "with open(libs_text_files, 'r') as f:\n",
    "    for line in f:\n",
    "        samp, lib, path = line.strip().split()\n",
    "        if f\"{lib}_1\" not in rev_libs_sample_dict:\n",
    "            rev_libs_sample_dict[f\"{lib}_1\"] = samp\n",
    "            lib = lib + \"_1\"\n",
    "        elif f\"{lib}_2\" not in rev_libs_sample_dict:\n",
    "            rev_libs_sample_dict[f\"{lib}_2\"] = samp\n",
    "            lib = lib + \"_2\"\n",
    "        elif f\"{lib}_3\" not in rev_libs_sample_dict:\n",
    "            rev_libs_sample_dict[f\"{lib}_3\"] = samp\n",
    "            lib = lib + \"_3\"\n",
    "        libs_sample_dict[samp] = lib\n",
    "        libs_dir_dict[lib] = Path(path)\n",
    "pprint(libs_sample_dict)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6141bd2244b761a6",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "counts_df = pd.read_csv(counts_file, sep=\"\\t\").rename(columns={\"Unnamed: 0\": \"gene_id\"})\n",
    "counts_df.rename(columns=libs_sample_dict, inplace=True)\n",
    "counts_df.sort_values(\"wt_1\", ascending=False).query(\"wt_1 > 0\").head(50)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9532370e446ff9ff",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# This is the secret sauce, to go from a two column df where one of the columns in the count of the other column INTO a single column df with the gene_id repeated the correct number of times\n",
    "\n",
    "def get_gene_id_series_from_counts_df(counts_df: pd.DataFrame, target_lib: str) -> pd.Series:\n",
    "    test_df = counts_df.copy()[[\"gene_id\", target_lib]].query(f\"{target_lib} > 0\")\n",
    "    return test_df.loc[test_df.index.repeat(test_df[target_lib])].reset_index(drop=True)[\"gene_id\"]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5d920d675d529dc9",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def get_unique_genes_count(subsampled_series: pd.Series) -> int:\n",
    "    # return len(set(subsampled_series))\n",
    "    return len(np.unique(subsampled_series))\n",
    "    # return subsampled_series.nunique()\n",
    "\n",
    "def subsample_gene_repeats(unsampled_series: pd.Series, target_count: int) -> pd.Series:\n",
    "    rng = np.random.default_rng()\n",
    "    return rng.choice(unsampled_series, size=target_count, replace=False)\n",
    "\n",
    "def get_unique_gene_count_averaged(unsampled_series: pd.Series, target_count: int = 1000, n_repeats: int = 10) -> int:\n",
    "    unsampled_array = unsampled_series.to_numpy()\n",
    "    unique_counts = np.empty(n_repeats)\n",
    "    for i in range(n_repeats):\n",
    "        subsampled_array = subsample_gene_repeats(unsampled_array, target_count)\n",
    "        unique_counts[i] = get_unique_genes_count(subsampled_array)\n",
    "    return np.mean(unique_counts)\n",
    "\n",
    "test_lib = get_gene_id_series_from_counts_df(counts_df, \"wt_1\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ba8ebf01e68e68be",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "libs_to_run = [\n",
    "    \"oldN2\",\n",
    "    # \"oldS6\",\n",
    "    \"newerN2\",\n",
    "    \"newerS6\",\n",
    "    \"newerS5\",\n",
    "    \"thirdN2\",\n",
    "    \"thirdS5\",\n",
    "    \"thirdS6\",\n",
    "    # \"temp25cN2\",\n",
    "    # \"temp25cS5\",\n",
    "    # \"temp25cS6\",\n",
    "    # \"temp25cS7\",\n",
    "]\n",
    "obj_dict = {}\n",
    "compressed_df_dict = {}\n",
    "for lib in libs_to_run:\n",
    "    print(f\"\\nLoading {lib}...\", end=\"\")\n",
    "    obj = npCommon.NanoporeRun(run_nickname=lib, pre_load_items=False)\n",
    "    obj_dict[lib] = obj\n",
    "    compressed_df_dict[lib] = obj.load_compressedOnGenes()\n",
    "    print(\" Done!\")\n",
    "    # About 45 seconds total, unless loaded recently which is about 5 seconds"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "64782749b14426dd",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "read_df_dict = {\"wt_1\": get_gene_id_series_from_counts_df(counts_df, \"wt_1\"),\n",
    "                \"wt_2\": get_gene_id_series_from_counts_df(counts_df, \"wt_2\"),}\n",
    "for lib, df in compressed_df_dict.items():\n",
    "    simplified_count_df = df[[\"gene_id\", \"read_hits\"]].query(\"read_hits > 0\")\n",
    "    reads_df = simplified_count_df.loc[simplified_count_df.index.repeat(simplified_count_df[\"read_hits\"])].reset_index(drop=True)[\"gene_id\"]\n",
    "    read_df_dict[lib] = reads_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ddd72bdcc61379fa",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# x_values = np.arange(1_000, 1_500_000, 1_000)\n",
    "# y_values_dict = {}\n",
    "# for lib, read_like_df in read_df_dict.items():\n",
    "#     y_values = []\n",
    "#     working = True\n",
    "#     iterator = tqdm(x_values, desc=f\"Running for {lib}\")\n",
    "#     for x in iterator:\n",
    "#         if x >= read_like_df.shape[0]:\n",
    "#             working = False\n",
    "#         if working:\n",
    "#             y_values.append(get_unique_gene_count_averaged(read_like_df, target_count=x, n_repeats=10))\n",
    "#         else:\n",
    "#             y_values.append(None)\n",
    "#     y_values_dict[lib] = y_values"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "561a44ca06997a8d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "for lib, df in read_df_dict.items():\n",
    "    print(f\"{lib:>10}: {df.shape[0]:>10,}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "44f69607f4fc761",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from joblib import Parallel, delayed\n",
    "N_REPEATS = 10\n",
    "\n",
    "def process_library(lib, read_like_df, x_values, with_tqdm=False) -> Tuple[str, np.ndarray]:\n",
    "    y_values = np.empty(len(x_values), dtype=object)\n",
    "    cutoff = read_like_df.shape[0]\n",
    "    if with_tqdm:\n",
    "        iterator = tqdm(enumerate(x_values), desc=f\"Running for {lib}\", total=len(x_values))\n",
    "    else:\n",
    "        iterator = enumerate(x_values)\n",
    "    for idx, x in iterator:\n",
    "        if x >= cutoff:\n",
    "            y_values[idx] = get_unique_genes_count(read_like_df)\n",
    "            break\n",
    "        y_values[idx] = get_unique_gene_count_averaged(read_like_df, target_count=x, n_repeats=N_REPEATS)\n",
    "    return lib, y_values\n",
    "\n",
    "# x_values = np.arange(10_000, 10_000_000, 10_000)  # TODO: Maybe try a log of x values, so more points at the lower end and less up high where it matters less?\n",
    "x_values = np.geomspace(1_000, 10_000_000, 200, dtype=int)\n",
    "# results = Parallel(n_jobs=-1)(delayed(process_library)(lib, read_like_df, x_values) for lib, read_like_df in tqdm(read_df_dict.items(), desc=\"Processing Libraries\"))\n",
    "results = []\n",
    "for lib, read_like_df in read_df_dict.items():\n",
    "    print(f\"{lib} has a total read count of {read_like_df.shape[0]:,}\")\n",
    "    results.append(process_library(lib, read_like_df, x_values, with_tqdm=True))\n",
    "y_values_dict = {lib: y_values for lib, y_values in results}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3206a59d6ad06a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# We need to save the results so we don't have to re-run this every time!!\n",
    "values_dict = y_values_dict.copy()\n",
    "values_dict['x_values'] = x_values\n",
    "\n",
    "save_dir = Path(\"./data/saturationAnalysis\")\n",
    "save_dir.mkdir(exist_ok=True, parents=True)\n",
    "with open(save_dir / \"saturationAnalysis.pkl\", 'wb') as f:\n",
    "    pkl.dump(values_dict, f)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a1cda25c6d30effd",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Let's plot the results:\n",
    "# y_values on y axis, x_values on x axis:\n",
    "fig, axes = plt.subplots(1,2, figsize=(5, 4), sharey=True)\n",
    "# Let's arbitrarily choose colors for each lib in y_values_dict\n",
    "colors = sea.color_palette(\"husl\", n_colors=len(y_values_dict))\n",
    "# Maybe let's make a real color and line_style dict:\n",
    "# WT will be solid lines, smg-5 will be dashed, and smg-6 will be dot-dashed\n",
    "# RNA-seq will be black and grey, and nanopore reps will be blue, orange, and green for 1, 2, and 3 respectively\n",
    "# I'd also like the point shapes for the total unique genes to correlate with the line style\n",
    "solid, dashed, dot_dashed = \"-\", \"--\", \"-.\"\n",
    "# colors_in_255 = ((15, 15, 15), (25, 25, 25), (230, 159, 0), (0, 158, 115), (213, 70, 0))\n",
    "# grey1, grey2, rep2_color, rep3_color, rep1_color = colors_in_float = [(c[0] / 255, c[1] / 255, c[2] / 255) for c in colors_in_255]\n",
    "grey1, grey2, rep1_color, rep2_color, rep3_color = \"#404040ff\", \"#707070ff\", \"#56b4e9ff\", \"#e69f00ff\", \"#009e73ff\"\n",
    "color_and_line_style_dict = {\n",
    "    \"wt_1\": (grey1,\n",
    "             solid,\n",
    "             \"$\\mathbf{s1}$\"),  # RNA-seq 1\n",
    "    \"wt_2\": (grey2,\n",
    "             solid,\n",
    "             \"$\\mathbf{s2}$\"),  # RNA-seq 2\n",
    "    \"oldN2\": (rep1_color,\n",
    "              solid,\n",
    "             \"$\\mathbf{1}$\"),  # WT rep 1\n",
    "    \"newerN2\": (rep2_color,\n",
    "                solid,\n",
    "                \"$\\mathbf{2}$\"),  # WT rep 2\n",
    "    \"thirdN2\": (rep3_color,\n",
    "                solid,\n",
    "                \"$\\mathbf{3}$\"),  # WT rep 3\n",
    "    \"oldS6\": (rep1_color,\n",
    "              dot_dashed,\n",
    "             \"$\\mathbf{1}$\"),  # smg-6 rep 1\n",
    "    \"newerS6\": (rep2_color,\n",
    "                dot_dashed,\n",
    "                \"$\\mathbf{2}$\"),  # smg-6 rep 2\n",
    "    \"thirdS6\": (rep3_color,\n",
    "                dot_dashed,\n",
    "                \"$\\mathbf{3}$\"),  # smg-6 rep 3\n",
    "    \"oldS5\": (rep1_color,\n",
    "              dashed,\n",
    "             \"$\\mathbf{1}$\"),  # smg-5 rep 1\n",
    "    \"newerS5\": (rep2_color,\n",
    "                dashed,\n",
    "                \"$\\mathbf{2}$\"),  # smg-5 rep 2\n",
    "    \"thirdS5\": (rep3_color,\n",
    "                dashed,\n",
    "                \"$\\mathbf{3}$\"),  # smg-5 rep 3\n",
    "}\n",
    "\n",
    "for lib, y_values in list(y_values_dict.items())[::-1]:\n",
    "    # I need to trim the y_values to get rid of the None values, and make a trimmed version of x_values to match\n",
    "    trimmed_y_values = np.array([y for y in y_values if y is not None])\n",
    "    trimmed_x_values = x_values[:len(trimmed_y_values)]\n",
    "    print(f\"{lib:>10}: {trimmed_y_values[-1]:>10,} @ {trimmed_x_values[-1]:>10,}\")\n",
    "    color, line_style, point_shape = color_and_line_style_dict[lib]\n",
    "    for i, ax in enumerate(axes):\n",
    "        ax.plot(trimmed_x_values, trimmed_y_values, label=lib, color=color, linestyle=line_style)\n",
    "        ax.plot(trimmed_x_values[-1], trimmed_y_values[-1], marker=point_shape, color='k', markerfacecolor=color, markersize=15, zorder=10)\n",
    "for ax in axes[::-1]:\n",
    "    ax.set_xlabel(\"Total Reads\")\n",
    "    # ax.set_xscale(\"log\")\n",
    "    # ax.set_yscale(\"log\")\n",
    "axes[0].set_xlim(0, 9_000_000)\n",
    "axes[1].set_xlim(0, 1_500_000)\n",
    "\n",
    "ax.set_ylabel(\"Unique Genes\")\n",
    "ax.grid(True, which=\"both\")\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "save_dir = Path(\"./plots/saturationAnalysis\")\n",
    "save_dir.mkdir(exist_ok=True, parents=True)\n",
    "plt.savefig(save_dir / \"saturationAnalysis.png\", dpi=300)\n",
    "plt.savefig(save_dir / \"saturationAnalysis.svg\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5db69b5577dee826",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "N_REPEATS = 10\n",
    "N_FRACTIONS = 10\n",
    "\n",
    "\n",
    "def subsample_gene_repeats_fractional(unsampled_series: pd.Series, target_frac: float) -> pd.Series:\n",
    "    rng = np.random.default_rng()\n",
    "    target_size = int(len(unsampled_series) * target_frac)\n",
    "    return rng.choice(unsampled_series, size=target_size, replace=False)\n",
    "\n",
    "def get_unique_gene_count_averaged_fractional_with_count(unsampled_series: pd.Series, target_frac: float, n_repeats: int = 10) -> Tuple[float, float]:\n",
    "    unsampled_array = unsampled_series.to_numpy()\n",
    "    unique_counts = np.empty(n_repeats)\n",
    "    total_reads = np.empty(n_repeats)\n",
    "    for i in range(n_repeats):\n",
    "        subsampled_array = subsample_gene_repeats_fractional(unsampled_array, target_frac)\n",
    "        total_reads[i] = len(subsampled_array)  # len is about 2x faster than .shape[0] (non-rigorous testing)\n",
    "        unique_counts[i] = get_unique_genes_count(subsampled_array)\n",
    "    return np.mean(unique_counts), np.mean(total_reads)\n",
    "\n",
    "def process_library_fractional(lib: str, read_like_df: pd.Series, fractions: np.array, with_tqdm=False) -> Tuple[str, np.ndarray, np.ndarray]:\n",
    "    y_values = np.empty(len(fractions), dtype=object)\n",
    "    total_reads = np.empty(len(fractions), dtype=object)\n",
    "    if with_tqdm:\n",
    "        iterator = tqdm(enumerate(fractions), desc=f\"Running for {lib}\", total=len(fractions))\n",
    "    else:\n",
    "        iterator = enumerate(fractions)\n",
    "    for idx, frac in iterator:\n",
    "        iterator.set_postfix_str(f\"frac: {frac:3.1%}\")\n",
    "        y_values[idx], total_reads[idx] = get_unique_gene_count_averaged_fractional_with_count(read_like_df, target_frac=frac, n_repeats=N_REPEATS)\n",
    "    return lib, y_values, total_reads\n",
    "\n",
    "fractions = np.linspace(1 / N_FRACTIONS,  # Start (not 0)\n",
    "                        1,  # End\n",
    "                        N_FRACTIONS) # Number of points\n",
    "results_fractional = []\n",
    "for lib, read_like_df in read_df_dict.items():\n",
    "    results_fractional.append(process_library_fractional(lib, read_like_df, fractions, with_tqdm=True))\n",
    "y_values_dict_fractional = {lib: y_values for lib, y_values, _ in results_fractional}\n",
    "total_reads_dict_fractional = {lib: total_reads for lib, _, total_reads in results_fractional}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eb9b297b279c056",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Let's plot the results:\n",
    "# y_values on y axis, total_reads on x axis:\n",
    "fig, ax = plt.subplots(figsize=(6, 8))\n",
    "# Let's arbirarily choose colors for each lib in y_values_dict_fractional\n",
    "colors = sea.color_palette(\"husl\", n_colors=len(y_values_dict_fractional))\n",
    "\n",
    "\n",
    "for idx, (lib, y_values) in enumerate(y_values_dict_fractional.items()):\n",
    "    print(f\"{lib:>10}: {y_values[-1]:>10,}\")\n",
    "    color = colors[idx]\n",
    "    total_reads = total_reads_dict_fractional[lib]\n",
    "    ax.plot(total_reads, y_values, label=lib, color=color)\n",
    "    ax.plot(total_reads[-1], y_values[-1], \"o\", color=color)\n",
    "ax.set_xlabel(\"Total Reads\")\n",
    "ax.set_ylabel(\"Unique Genes\")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.grid(True, which=\"both\")\n",
    "ax.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3cc33702cd637148",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Maybe try to optimize with: the weights option on the pd.DataFrame.sample method\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sample.html\n",
    "# Ideally, I'd do a direct comparison with this super slow method above and the weighted method as discussed in the link\n",
    "# I think there is some math here where I could sample with weights, then divide the weights by the fraction of the total reads to get the correct number of reads at that depth, then perform a cutoff for >1 reads?\n",
    "# TODO: Try this out!!"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "907564da7c24b726",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Plan:\n",
    "# 1. Divide the gene counts by the total number of reads to get the fraction of reads for each gene\n",
    "# 2. Sample with weights based on the fraction of reads (but how many are we sampling? since our rows are genes here, not reads) .... DAMMIT.\n",
    "\n",
    "# TODO: We should probably do this with rand choice for sampling, as this can take weights and numbers of samples!!"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "53846b80b836bf74",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
