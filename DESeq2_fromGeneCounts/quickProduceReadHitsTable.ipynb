{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# quickProduceReadHitsTable.ipynb\n",
    "## Marcus Viscardi,    April 24, 2024\n",
    "\n",
    "I am just taking the first few parts of DESeq2_fromGeneCountsDF.ipynb and putting them here for easier access."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b6abad1440192d40"
  },
  {
   "cell_type": "code",
   "source": [
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects import pandas2ri\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import seaborn as sea\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import nanoporePipelineCommon as npCommon\n",
    "\n",
    "from icecream import ic\n",
    "from datetime import datetime\n",
    "\n",
    "def __time_formatter__():\n",
    "    now = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    return f\"ic: {now} | > \"\n",
    "ic.configureOutput(prefix=__time_formatter__)\n",
    "\n",
    "\n",
    "ic(\"Imports done.\")\n",
    "working_dir = Path.cwd()\n",
    "_ = ic(working_dir)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc7508326ee9fc54",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "gene_id_gene_name_df = npCommon.gene_names_to_gene_ids()\n",
    "gene_id_gene_name_df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "obj_dict = {}\n",
    "libs_to_run = [\n",
    "    # \"oldN2\",\n",
    "    # \"oldS6\",\n",
    "    # \"newerN2\",\n",
    "    # \"newerS6\",\n",
    "    # \"newerS5\",\n",
    "    # \"thirdN2\",\n",
    "    # \"thirdS5\",\n",
    "    # \"thirdS6\",\n",
    "    # \"polyA\",\n",
    "    \"polyA1\",\n",
    "    \"polyA2\",\n",
    "    \"polyA3\",\n",
    "    \"totalRNA1\",\n",
    "    \"totalRNA2\",\n",
    "    \"totalRNA3\",\n",
    "]\n",
    "for lib in libs_to_run:\n",
    "    print(f\"\\nLoading {lib}...\", end=\"\")\n",
    "    obj_dict[lib] = npCommon.NanoporeRun(run_nickname=lib)\n",
    "    print(\" Done!\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b9752ee006f8d024",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# compressedOnGenes_dict = {}\n",
    "# for lib, obj in obj_dict.items():\n",
    "#     compressedOnGenes_dict[lib] = obj.load_compressedOnGenes()  # Looks like the old N2 library had a read cutoff of 5 while everything else had no cutoff!!\n",
    "#     # ic(obj)\n",
    "# read_hits_series_dict = {}\n",
    "# for lib, df in compressedOnGenes_dict.items():\n",
    "#     print(f\"Pre-cutdown:  {lib} - {df.shape[0]:,} Genes\", end=\" \")\n",
    "#     # # TODO: Eventually, I should rerun the compressing for oldN2 without the cutoff!!!\n",
    "#     # df = df.query(\"read_hits >= 5\")\n",
    "#     print(f\"Post-cutdown: {lib} - {df.shape[0]:,} Genes\")\n",
    "#     # print(df.head())\n",
    "#     hits_series = df[[\n",
    "#         # 'gene_id',\n",
    "#         'read_hits',\n",
    "#                       ]]# .set_index('gene_id')\n",
    "#     print(hits_series)\n",
    "#     hits_series.rename(columns={'read_hits': lib}, inplace=True)\n",
    "#     read_hits_series_dict[lib] = hits_series\n",
    "# read_hits_table = pd.concat(read_hits_series_dict.values(), axis=1).fillna(0)\n",
    "# read_hits_table.to_csv(working_dir / f\"read_hits_table_{'-'.join(libs_to_run)}.csv\")\n",
    "# print(f\"Saved read_hits_table_{'-'.join(libs_to_run)}.csv to {working_dir}!\")\n",
    "# read_hits_table.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f85aa66e902e8d0d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# From fresh featureCounts runs\n",
    "\n",
    "Another way to go about this would be to run FeatureCounts for each of the libraries using their BAM files, then use the resulting gene count tables to make a read hits table. This would be a bit more work, but would also be a bit more accurate. I will try this next."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8cf97dce6c8ec892"
  },
  {
   "cell_type": "code",
   "source": [
    "import subprocess\n",
    "\n",
    "regen = True\n",
    "threads = 32\n",
    "input_bam_paths = {lib_name: obj.bam_path for lib_name, obj in obj_dict.items()}\n",
    "overall_output_dir = working_dir / \"featureCounts_testing\"\n",
    "overall_output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "for lib, lib_obj in obj_dict.items():\n",
    "    bam_path = lib_obj.bam_path\n",
    "    gtf_path = lib_obj.gtf_path\n",
    "    output_dir = overall_output_dir / lib\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    assigned_read_output_file = output_dir / (str(Path(bam_path).name) + \".featureCounts\")\n",
    "    gene_count_output_file = output_dir / f\"{npCommon.get_dt(for_file=True)}_{lib}_featureCounts\"\n",
    "    if regen or not gene_count_output_file.exists():\n",
    "        featCounts_call = (f\"featureCounts -L -T {threads} -R CORE -a {gtf_path} \"\n",
    "                           f\"-o {output_dir}/{npCommon.get_dt(for_file=True)}_{lib}_featureCounts \"\n",
    "                           f\"--largestOverlap -s 1 \"\n",
    "                           f\"{bam_path}\")\n",
    "        # TODO: Turn back on\n",
    "        subprocess.run(featCounts_call, shell=True)\n",
    "    else:\n",
    "        print(f\"Already ran {lib}! w/ input file {bam_path}, gtf file {gtf_path} and output file {gene_count_output_file}!\")\n",
    "    \n",
    "    # These would be names for the pure featureCounts output: names=[\"GeneID\", \"Chr\", \"Start\", \"End\", \"Strand\", \"Length\", lib]\n",
    "    featCounts_df = pd.read_csv(gene_count_output_file, sep=\"\\t\", skiprows=2, names=[\"GeneID\", \"Chr\", \"Start\", \"End\", \"Strand\", \"Length\", lib])\n",
    "    print(featCounts_df.head())\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2fea8791f0a0a2f7",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "genes_to_print = [\n",
    "    'WBGene00023068',\n",
    "    'WBGene00023067',\n",
    "]\n",
    "\n",
    "featCounts_df.query(f\"index in @genes_to_print\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "64407a9bc91b1be",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "regen = False\n",
    "gtf_path = obj_dict['polyA1'].gtf_path\n",
    "bam_paths_dict = {lib: obj.bam_path for lib, obj in obj_dict.items()}\n",
    "bam_paths = [str(lib_bam_path) for lib, lib_bam_path in bam_paths_dict.items()]\n",
    "libs = list(obj_dict.keys())\n",
    "output_dir = overall_output_dir / \"allLibs_fractional\"\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "gene_count_alllibs_output_file = output_dir / f\"{npCommon.get_dt(for_file=True)}_{'-'.join(libs)}_featureCounts\"\n",
    "if regen or not gene_count_alllibs_output_file.exists():\n",
    "    featCounts_call = (f\"featureCounts -L -T {threads} -R CORE -a {gtf_path} \"\n",
    "                       f\"-o {gene_count_alllibs_output_file} \"\n",
    "                       # f\"-O \"  # this will count all features that a read overlaps, instead of tossing it!\n",
    "                       # f\"--fraction \"\n",
    "                       f\"--largestOverlap -s 1 \"\n",
    "                       f\"{' '.join(bam_paths)}\")\n",
    "    subprocess.run(featCounts_call, shell=True)\n",
    "else:\n",
    "    print(f\"Already ran {'-'.join(libs)}! w/ input files {bam_paths}, gtf file {gtf_path} and output file {gene_count_alllibs_output_file}!\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca788d16c6f9d860",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "rev_bam_paths_dict = {str(v): k for k, v in bam_paths_dict.items()}\n",
    "print(rev_bam_paths_dict)\n",
    "\n",
    "featCounts_alllibs_df = pd.read_csv(gene_count_alllibs_output_file,\n",
    "                                    sep=\"\\t\",\n",
    "                                    skiprows=1,\n",
    "                                    # names=[\"GeneID\", \"Chr\", \"Start\", \"End\", \"Strand\", \"Length\"] + libs,\n",
    "                                    )\n",
    "featCounts_alllibs_df.rename(columns={\"Geneid\": \"Gene_ID\"}, inplace=True)\n",
    "featCounts_alllibs_df.rename(columns=rev_bam_paths_dict, inplace=True)\n",
    "featCounts_alllibs_df.set_index(\"Gene_ID\", inplace=True)\n",
    "featCounts_alllibs_simple_df = featCounts_alllibs_df[libs].copy()\n",
    "featCounts_alllibs_simple_df[\"sum\"] = featCounts_alllibs_simple_df.sum(axis=1)\n",
    "featCounts_alllibs_simple_df.sort_values(\"sum\", ascending=False, inplace=True)\n",
    "featCounts_alllibs_simple_df.head(25)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "82e3258262aa295c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "genes_to_print = [\n",
    "    'WBGene00023068',\n",
    "    'WBGene00023067',\n",
    "]\n",
    "\n",
    "featCounts_alllibs_simple_df.query(f\"index in @genes_to_print\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1357c2bd645a635d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "featCounts_alllibs_simple_df = featCounts_alllibs_simple_df[['polyA1', 'polyA2', 'polyA3', 'totalRNA2', 'totalRNA3']].copy()\n",
    "for col in featCounts_alllibs_simple_df.columns:\n",
    "    print(f\"{col} total assigned reads: {featCounts_alllibs_simple_df[col].sum():,}\")\n",
    "featCounts_alllibs_simple_df.head(50)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b4132d95fd94423",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "featCounts_alllibs_simple_df.to_csv(working_dir / f\"featureCounts_readCounts_{'-'.join(featCounts_alllibs_simple_df.columns)}.csv\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f62e21139eca50d3",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "genes_to_print = [\n",
    "    'WBGene00023068',\n",
    "    'WBGene00023067',\n",
    "    'WBGene00004446',\n",
    "    'WBGene00004419',\n",
    "    'WBGene00004451',\n",
    "    'WBGene00004432',\n",
    "]\n",
    "\n",
    "featCounts_alllibs_simple_df.query(f\"index in @genes_to_print\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "60362543abe37a9d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "cea3f38902277608",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
